{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<center> <h3 style=\"color:blue\">========================================================</h3> </center>\n",
    "<center> <h3 style=\"color:green\">In the Name of Allah, the Most Beneficent, the Most Merciful</h3> </center>\n",
    "<center> <h3 style=\"color:blue\">========================================================</h3> </center>\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        *----------------------------- AUTHOR_DETAILS -------------------------------*\n",
    "        |                                                                            |\n",
    "        |        Project Title  = GPA Prediction System                              |\n",
    "        |                                                                            |\n",
    "        |        Author         = Mr. Atif Raza Chaudary                             |\n",
    "        |                                                                            |\n",
    "        |        Copyright      = Copyright (C) 2020 Mr. Atif Raza Chaudary          |\n",
    "        |                                                                            |\n",
    "        |        License        = Public Domain                                      |\n",
    "        |                                                                            |\n",
    "        |        Version        = 1.0                                                |\n",
    "        |                                                                            |\n",
    "        *----------------------------------------------------------------------------*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<center> <h2 style=\"color:green\">-------------------- PROJECT PURPOSE --------------------</h2> </center>\n",
    "<br>\n",
    "<center><h3>\n",
    "The main purpose of this Project is to demonstrate how the GPA Prediction Problem can be treated as a Supervised Machine Learning Problem using Python and Scikit-learn Machine Learning Toolkit </h3>\n",
    "<br>\n",
    "<center><h3> For this Purpose, In Sha Allah, we will execute the Machine Learning Cycle </h3>\n",
    "<br>\n",
    "<center> <h2 style=\"color:green\">-------------------------------------------------------------------------</h2> </center>\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red\">GPA Prediction System â€“ Machine Learning Cycle</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Cycle\n",
    "\n",
    "### Four phases of a Machine Learning Cycle are\n",
    "\n",
    "### Training Phase\n",
    "\n",
    "    Build the Model using Training Data\n",
    "\n",
    "### Testing Phase\n",
    "\n",
    "     Evaluate the performance of Model using Testing Data\n",
    "\n",
    "### Application Phase\n",
    "\n",
    "     Deploy the Model in the Real-world, to predict Real-time unseen Data\n",
    "\n",
    "### Feedback Phase\n",
    "\n",
    "    Take Feedback from the Users and Domain Experts to improve the Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red\">Executing Machine Learning Cycle Using a Single File</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Sha Allah, we will follow the following Steps to execute the Machine Learning Cycle Using a Single File\n",
    "\n",
    "#### Step 1: Import Libraries\n",
    "\n",
    "#### Step 2: Load Sample Data\n",
    "\n",
    "#### Step 3: Understand and Pre-process Sample Data\n",
    "    \n",
    "    Step 3.1: Understand Sample Data\n",
    "    \n",
    "    Step 3.2: Pre-process Sample Data\n",
    "\n",
    "#### Step 4: Feature Extraction \n",
    "\n",
    "#### Step 5: Label Encoding (Input and Output is converted in Numeric Representation)\n",
    "\n",
    "    Step 5.1: Train the Label Encoder\n",
    "\n",
    "    Step 5.2: Label Encode the Output\n",
    "\n",
    "    Step 5.3: Label Encode the Input \n",
    "\n",
    "#### Step 6: Execute the Training Phase\n",
    "\n",
    "    Step 6.1: Splitting Sample Data into Training Data and Testing Data \n",
    "    \n",
    "    Step 6.2: Splitting Input Vectors and Outputs/Labels of Training Data\n",
    "    \n",
    "    Step 6.3: Train the Support Vector Regressor\n",
    "    \n",
    "    Step 6.4: Save the Trained Model\n",
    "\n",
    "\n",
    "#### Step 7: Execute the Testing Phase \n",
    "\n",
    "    Step 7.1: Splitting Input Vectors and Output/Labels of Testing Data\n",
    "    \n",
    "    Step 7.2: Load the Saved Model\n",
    "    \n",
    "    Step 7.3: Evaluate the Performance of Trained Model\n",
    "    \n",
    "        Step 7.3.1: Make Predictions from the Model on Testing Data\n",
    "    \n",
    "    Step 7.4: Calculate the Mean Absolute Error.\n",
    "\n",
    "#### Step 8: Execute the Application Phase \n",
    "\n",
    "    Step 8.1: Take Input from User \n",
    "    \n",
    "    Step 8.2: Convert User Input into Feature Vector (Exactly Same as Feature Vectors of Sample Data)\n",
    "    \n",
    "    Step 8.3: Label Encoding of Feature Vector (Exactly Same as Label Encoded Feature Vectors of Sample Data)\n",
    "    \n",
    "    Step 8.4: Load the Saved Model\n",
    "    \n",
    "    Step 8.5: Model Prediction\n",
    "        \n",
    "        Step 8.5.1: Apply Model on the Label Encoded Feature Vector of unseen instance and return Prediction to the User\n",
    "\n",
    "\n",
    "#### Step 9: Execute the Feedback Phase \n",
    "\n",
    "#### Step 10: Improve the Model based on Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import re\n",
    "import scipy\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from prettytable import PrettyTable\n",
    "from astropy.table import Table, Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Load Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Sample Data:\n",
      "============\n",
      "\n",
      "    Matric Marks  FSc Marks   GPA\n",
      "0            852        783  3.07\n",
      "1            808        801  3.36\n",
      "2            840        806  3.77\n",
      "3            824        720  2.98\n",
      "4            902        789  3.16\n",
      "5            926        791  3.23\n",
      "6            770        658  2.97\n",
      "7            690        626  2.72\n",
      "8            729        713  3.26\n",
      "9            781        597  3.30\n",
      "10           591        692  2.73\n",
      "11           806        844  3.43\n",
      "12           818        720  3.21\n",
      "13           828        748  2.84\n",
      "14           770        698  2.64\n",
      "15           594        715  3.47\n",
      "16           871        789  3.35\n",
      "17           785        718  3.29\n",
      "18           854        752  3.54\n",
      "19           859        673  2.95\n",
      "20           790        769  3.13\n",
      "21           800        665  2.96\n",
      "22           906        764  3.00\n",
      "23           693        690  3.07\n",
      "24           745        667  3.33\n",
      "25           717        720  3.26\n",
      "26           696        725  2.45\n",
      "27           697        729  3.34\n",
      "28           867        735  3.05\n",
      "29           831        723  2.94\n",
      "30           732        761  3.38\n",
      "31           802        686  3.38\n",
      "32           715        688  2.75\n",
      "33           745        642  2.81\n",
      "34           758        851  3.57\n",
      "35           764        735  3.12\n",
      "36           822        674  2.90\n",
      "37           855        839  3.58\n",
      "38           886        821  3.56\n",
      "39           538        615  2.96\n",
      "40           954        866  3.59\n",
      "41           764        677  2.30\n",
      "42           893        721  2.87\n",
      "43           749        723  2.87\n",
      "44           798        764  3.45\n",
      "45           729        779  2.84\n",
      "46           714        700  3.20\n",
      "47           822        683  3.36\n",
      "48           855        711  2.95\n",
      "49           803        761  3.07\n",
      "50           718        688  2.73\n",
      "51           679        702  3.26\n",
      "52           850        833  3.31\n",
      "53           622        720  3.11\n",
      "54           803        650  3.35\n",
      "55           734        800  2.96\n",
      "56           725        792  3.26\n",
      "57           611        685  2.55\n",
      "58           692        617  1.33\n",
      "59           693        712  3.31\n",
      "60           641        740  3.01\n",
      "61           734        706  3.48\n",
      "62           700        775  2.81\n",
      "63           756        761  3.53\n",
      "64           739        685  2.60\n",
      "65           764        608  2.89\n",
      "66           794        694  2.86\n",
      "67           846        766  3.56\n",
      "68           632        702  2.25\n",
      "69           858        582  2.63\n",
      "70           852        632  3.26\n",
      "71           526        630  2.55\n",
      "72           811        586  2.40\n",
      "73           748        674  2.46\n",
      "74           688        624  2.81\n",
      "75           849        810  3.40\n",
      "76           881        802  3.56\n",
      "77           660        552  2.88\n",
      "78           758        714  2.83\n",
      "79           850        768  2.85\n",
      "80           578        648  2.71\n",
      "81           905        762  2.88\n",
      "82           806        684  2.63\n",
      "83           686        798  2.63\n",
      "84           784        676  2.88\n",
      "85           729        716  3.01\n",
      "86           826        750  2.60\n",
      "87           622        616  2.41\n",
      "88           744        610  2.88\n",
      "89           895        646  2.83\n",
      "90           662        676  3.08\n",
      "91           743        756  2.88\n",
      "92           814        764  2.85\n",
      "93           686        548  2.68\n",
      "94           796        598  2.53\n",
      "95           783        650  2.93\n",
      "96           817        668  2.98\n",
      "97           803        650  3.35\n",
      "98           734        800  2.96\n",
      "99           725        792  3.26\n"
     ]
    }
   ],
   "source": [
    "# Load Sample Data\n",
    "\n",
    "''' \n",
    "*---------------------- LOAD_SAMPLE_DATA ------------------------*\n",
    "|     Function: read_csv()                                       |\n",
    "|             Purpose: Read a dataset in CSV file format         |\n",
    "|     Arguments:                                                 |\n",
    "|             path: Path to dataset file                         |\n",
    "|             dataset: Dataset file name                         |\n",
    "|     Return:                                                    |\n",
    "|             dataset: Dataset in DataFrame format               |\n",
    "*----------------------------------------------------------------*\n",
    "'''\n",
    " \n",
    "sample_data = pd.read_csv(\"sample-data.csv\")\n",
    "\n",
    "print(\"\\n\\nSample Data:\")\n",
    "print(\"============\\n\")\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "print(sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Understand and Pre-process Sample Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.1: Understand Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Attributes in Sample Data:\n",
      "==========================\n",
      "\n",
      "Index(['Matric Marks', 'FSc Marks', 'GPA'], dtype='object')\n",
      "\n",
      "\n",
      "Number of Instances in Sample Data: 100\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Understand Sample Data\n",
    "\n",
    "print(\"\\n\\nAttributes in Sample Data:\")\n",
    "print(\"==========================\\n\")\n",
    "\n",
    "print(sample_data.columns)\n",
    "\n",
    "print(\"\\n\\nNumber of Instances in Sample Data:\",sample_data[\"Matric Marks\"].count())\n",
    "print(\"========================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.2: Pre-process Sample Data\n",
    "    o\tSample Data is already Preprocessed\n",
    "    o\tNo Preprocessing needs to be Performed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Feature Extraction\n",
    "    o\tFeatures are already Extracted\n",
    "    o\tNo Feature Extraction needs to be Performed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Label Encoding the Sample Data (Input and Output is converted in Numeric Representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5.1: Train the Label Encoder\n",
    "     o  As Sample Data is already in Numeric Representation.\n",
    "     o  Therefore, we will not Label Encode the Sample Data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5.2: Label Encode the Output\n",
    "     o  As Output (GPA Attribute) is already in Numeric Representation.\n",
    "     o  Therefore, we will not Label Encode the Output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5.3: Label Encode the Input\n",
    "     o  As Input (Matric Marks and FSc Marks Attributes) is already in Numeric Representation.\n",
    "     o  Therefore, we will not Label Encode the Input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Execute the Training Phase "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6.1: Splitting Sample Data into Training Data and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Data:\n",
      "==============\n",
      "\n",
      "    Matric Marks  FSc Marks   GPA\n",
      "0            852        783  3.07\n",
      "1            808        801  3.36\n",
      "2            840        806  3.77\n",
      "3            824        720  2.98\n",
      "4            902        789  3.16\n",
      "5            926        791  3.23\n",
      "6            770        658  2.97\n",
      "7            690        626  2.72\n",
      "8            729        713  3.26\n",
      "9            781        597  3.30\n",
      "10           591        692  2.73\n",
      "11           806        844  3.43\n",
      "12           818        720  3.21\n",
      "13           828        748  2.84\n",
      "14           770        698  2.64\n",
      "15           594        715  3.47\n",
      "16           871        789  3.35\n",
      "17           785        718  3.29\n",
      "18           854        752  3.54\n",
      "19           859        673  2.95\n",
      "20           790        769  3.13\n",
      "21           800        665  2.96\n",
      "22           906        764  3.00\n",
      "23           693        690  3.07\n",
      "24           745        667  3.33\n",
      "25           717        720  3.26\n",
      "26           696        725  2.45\n",
      "27           697        729  3.34\n",
      "28           867        735  3.05\n",
      "29           831        723  2.94\n",
      "30           732        761  3.38\n",
      "31           802        686  3.38\n",
      "32           715        688  2.75\n",
      "33           745        642  2.81\n",
      "34           758        851  3.57\n",
      "35           764        735  3.12\n",
      "36           822        674  2.90\n",
      "37           855        839  3.58\n",
      "38           886        821  3.56\n",
      "39           538        615  2.96\n",
      "40           954        866  3.59\n",
      "41           764        677  2.30\n",
      "42           893        721  2.87\n",
      "43           749        723  2.87\n",
      "44           798        764  3.45\n",
      "45           729        779  2.84\n",
      "46           714        700  3.20\n",
      "47           822        683  3.36\n",
      "48           855        711  2.95\n",
      "49           803        761  3.07\n",
      "50           718        688  2.73\n",
      "51           679        702  3.26\n",
      "52           850        833  3.31\n",
      "53           622        720  3.11\n",
      "54           803        650  3.35\n",
      "55           734        800  2.96\n",
      "56           725        792  3.26\n",
      "57           611        685  2.55\n",
      "58           692        617  1.33\n",
      "59           693        712  3.31\n",
      "60           641        740  3.01\n",
      "61           734        706  3.48\n",
      "62           700        775  2.81\n",
      "63           756        761  3.53\n",
      "64           739        685  2.60\n",
      "65           764        608  2.89\n",
      "66           794        694  2.86\n",
      "67           846        766  3.56\n",
      "68           632        702  2.25\n",
      "69           858        582  2.63\n",
      "70           852        632  3.26\n",
      "71           526        630  2.55\n",
      "72           811        586  2.40\n",
      "73           748        674  2.46\n",
      "74           688        624  2.81\n",
      "75           849        810  3.40\n",
      "76           881        802  3.56\n",
      "77           660        552  2.88\n",
      "78           758        714  2.83\n",
      "79           850        768  2.85\n",
      "\n",
      "\n",
      "Testing Data:\n",
      "==============\n",
      "\n",
      "    Matric Marks  FSc Marks   GPA\n",
      "80           578        648  2.71\n",
      "81           905        762  2.88\n",
      "82           806        684  2.63\n",
      "83           686        798  2.63\n",
      "84           784        676  2.88\n",
      "85           729        716  3.01\n",
      "86           826        750  2.60\n",
      "87           622        616  2.41\n",
      "88           744        610  2.88\n",
      "89           895        646  2.83\n",
      "90           662        676  3.08\n",
      "91           743        756  2.88\n",
      "92           814        764  2.85\n",
      "93           686        548  2.68\n",
      "94           796        598  2.53\n",
      "95           783        650  2.93\n",
      "96           817        668  2.98\n",
      "97           803        650  3.35\n",
      "98           734        800  2.96\n",
      "99           725        792  3.26\n"
     ]
    }
   ],
   "source": [
    "# Splitting Sample Data into Training Data and Testing Data\n",
    "\n",
    "''' \n",
    "*------------------- SPLIT_SAMPLE_DATA ---------------------*\n",
    "|        Function: train_test_split()                       |\n",
    "|              Purpose: Split arrays or matrices into       |\n",
    "|                       random train and test subsets       |\n",
    "|        Arguments:                                         |\n",
    "|              arrays: sequence of indexables               |\n",
    "|              test_size: float or int                      |\n",
    "|        Return:                                            |\n",
    "|              splitting: list                              |\n",
    "*-----------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "training_data, testing_data = train_test_split( sample_data , test_size=0.2 , random_state=0 , shuffle = False)\n",
    "\n",
    "# Save the Training and Testing Data into CSV File \n",
    "\n",
    "training_data.to_csv(r'training-data.csv', index = False, header = True)\n",
    "testing_data.to_csv(r'testing-data.csv', index = False, header = True)\n",
    "\n",
    "# print Training and Testing Data\n",
    "\n",
    "print(\"\\n\\nTraining Data:\")\n",
    "print(\"==============\\n\")\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "print(training_data)\n",
    "print(\"\\n\\nTesting Data:\")\n",
    "print(\"==============\\n\")\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "print(testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2: Splitting Input Vectors and Outputs / Labels of Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Inputs Vectors (Feature Vectors) of Training Data:\n",
      "==================================================\n",
      "\n",
      "    Matric Marks  FSc Marks\n",
      "0            852        783\n",
      "1            808        801\n",
      "2            840        806\n",
      "3            824        720\n",
      "4            902        789\n",
      "5            926        791\n",
      "6            770        658\n",
      "7            690        626\n",
      "8            729        713\n",
      "9            781        597\n",
      "10           591        692\n",
      "11           806        844\n",
      "12           818        720\n",
      "13           828        748\n",
      "14           770        698\n",
      "15           594        715\n",
      "16           871        789\n",
      "17           785        718\n",
      "18           854        752\n",
      "19           859        673\n",
      "20           790        769\n",
      "21           800        665\n",
      "22           906        764\n",
      "23           693        690\n",
      "24           745        667\n",
      "25           717        720\n",
      "26           696        725\n",
      "27           697        729\n",
      "28           867        735\n",
      "29           831        723\n",
      "30           732        761\n",
      "31           802        686\n",
      "32           715        688\n",
      "33           745        642\n",
      "34           758        851\n",
      "35           764        735\n",
      "36           822        674\n",
      "37           855        839\n",
      "38           886        821\n",
      "39           538        615\n",
      "40           954        866\n",
      "41           764        677\n",
      "42           893        721\n",
      "43           749        723\n",
      "44           798        764\n",
      "45           729        779\n",
      "46           714        700\n",
      "47           822        683\n",
      "48           855        711\n",
      "49           803        761\n",
      "50           718        688\n",
      "51           679        702\n",
      "52           850        833\n",
      "53           622        720\n",
      "54           803        650\n",
      "55           734        800\n",
      "56           725        792\n",
      "57           611        685\n",
      "58           692        617\n",
      "59           693        712\n",
      "60           641        740\n",
      "61           734        706\n",
      "62           700        775\n",
      "63           756        761\n",
      "64           739        685\n",
      "65           764        608\n",
      "66           794        694\n",
      "67           846        766\n",
      "68           632        702\n",
      "69           858        582\n",
      "70           852        632\n",
      "71           526        630\n",
      "72           811        586\n",
      "73           748        674\n",
      "74           688        624\n",
      "75           849        810\n",
      "76           881        802\n",
      "77           660        552\n",
      "78           758        714\n",
      "79           850        768\n",
      "\n",
      "\n",
      "Outputs/Labels of Training Data:\n",
      "================================\n",
      "\n",
      "  GPA\n",
      "     GPA\n",
      "0   3.07\n",
      "1   3.36\n",
      "2   3.77\n",
      "3   2.98\n",
      "4   3.16\n",
      "5   3.23\n",
      "6   2.97\n",
      "7   2.72\n",
      "8   3.26\n",
      "9   3.30\n",
      "10  2.73\n",
      "11  3.43\n",
      "12  3.21\n",
      "13  2.84\n",
      "14  2.64\n",
      "15  3.47\n",
      "16  3.35\n",
      "17  3.29\n",
      "18  3.54\n",
      "19  2.95\n",
      "20  3.13\n",
      "21  2.96\n",
      "22  3.00\n",
      "23  3.07\n",
      "24  3.33\n",
      "25  3.26\n",
      "26  2.45\n",
      "27  3.34\n",
      "28  3.05\n",
      "29  2.94\n",
      "30  3.38\n",
      "31  3.38\n",
      "32  2.75\n",
      "33  2.81\n",
      "34  3.57\n",
      "35  3.12\n",
      "36  2.90\n",
      "37  3.58\n",
      "38  3.56\n",
      "39  2.96\n",
      "40  3.59\n",
      "41  2.30\n",
      "42  2.87\n",
      "43  2.87\n",
      "44  3.45\n",
      "45  2.84\n",
      "46  3.20\n",
      "47  3.36\n",
      "48  2.95\n",
      "49  3.07\n",
      "50  2.73\n",
      "51  3.26\n",
      "52  3.31\n",
      "53  3.11\n",
      "54  3.35\n",
      "55  2.96\n",
      "56  3.26\n",
      "57  2.55\n",
      "58  1.33\n",
      "59  3.31\n",
      "60  3.01\n",
      "61  3.48\n",
      "62  2.81\n",
      "63  3.53\n",
      "64  2.60\n",
      "65  2.89\n",
      "66  2.86\n",
      "67  3.56\n",
      "68  2.25\n",
      "69  2.63\n",
      "70  3.26\n",
      "71  2.55\n",
      "72  2.40\n",
      "73  2.46\n",
      "74  2.81\n",
      "75  3.40\n",
      "76  3.56\n",
      "77  2.88\n",
      "78  2.83\n",
      "79  2.85\n"
     ]
    }
   ],
   "source": [
    "# Splitting Input Vectors and Outputs / Labels of Training Data\n",
    "\n",
    "'''\n",
    "*---------------- SPLIT_INPUT_VECTORS_AND_LABELS --------------*\n",
    "|        Function: iloc()                                      |\n",
    "|            Purpose: Splitting Input Vector and Labels        |\n",
    "|        Arguments:                                            |\n",
    "|            Attribute: Name or Location Attribute to Split    |\n",
    "|        Return:                                               |\n",
    "|            Attribute: Split Attributes                       |\n",
    "*--------------------------------------------------------------*\n",
    "'''\n",
    "print(\"\\n\\nInputs Vectors (Feature Vectors) of Training Data:\")\n",
    "print(\"==================================================\\n\")\n",
    "input_vector_train = training_data.iloc[:, 0:2]\n",
    "print(input_vector_train)\n",
    "\n",
    "print(\"\\n\\nOutputs/Labels of Training Data:\")\n",
    "print(\"================================\\n\")\n",
    "print(\"  GPA\")\n",
    "output_label_train = training_data.iloc[:,2:]\n",
    "print(output_label_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3: Train the Support Vector Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training the Support Vector Regressor on Training Data\n",
      "========================================================\n",
      "\n",
      "\n",
      "Parameters and their values:\n",
      "============================\n",
      "\n",
      "LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_intercept=True,\n",
      "     intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
      "     random_state=None, tol=0.0001, verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Train the Support Vector Regressor\n",
    "\n",
    "''' \n",
    "*--------------- TRAIN_SUPPORT_VECTOR_REGRESSOR  ------------------*\n",
    "|       Function: svm.LinearSVR()                                        |\n",
    "|           Purpose: Train the Algorithm on Training Data          |\n",
    "|       Arguments:                                                 |\n",
    "|           Training Data: Provide Training Data to the Model      |\n",
    "|       Return:                                                    |\n",
    "|           Parameter: Model return the Training Parameters        |\n",
    "*------------------------------------------------------------------*\n",
    "'''\n",
    "print(\"\\n\\nTraining the Support Vector Regressor on Training Data\")\n",
    "print(\"========================================================\\n\")\n",
    "print(\"\\nParameters and their values:\")\n",
    "print(\"============================\\n\")\n",
    "svr_model = LinearSVR()\n",
    "svr_model.fit(input_vector_train,np.ravel(output_label_train))\n",
    "print(svr_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6.4: Save the Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Trained Models\n",
    "\n",
    "''' \n",
    "*--------------------- SAVE_THE_TRAINED_MODELS --------------------*\n",
    "|        Function: dump()                                          |\n",
    "|             Purpose: Save the Trained Model on your Hard Disk    |\n",
    "|        Arguments:                                                |\n",
    "|             Model: Model Objects                                 |\n",
    "|        Return:                                                   |\n",
    "|             File: Trained Model will be Saved on Hard Disk       |\n",
    "*------------------------------------------------------------------* \n",
    "'''\n",
    "\n",
    "# Save the Models in a Pkl File\n",
    "\n",
    "pickle.dump(svr_model, open('svr_trained_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Execute the Testing Phase "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7.1: Splitting Input Vectors and Outputs / Labels of Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Inputs Vectors (Feature Vectors) of Testing Data:\n",
      "=================================================\n",
      "\n",
      "    Matric Marks  FSc Marks\n",
      "80           578        648\n",
      "81           905        762\n",
      "82           806        684\n",
      "83           686        798\n",
      "84           784        676\n",
      "85           729        716\n",
      "86           826        750\n",
      "87           622        616\n",
      "88           744        610\n",
      "89           895        646\n",
      "90           662        676\n",
      "91           743        756\n",
      "92           814        764\n",
      "93           686        548\n",
      "94           796        598\n",
      "95           783        650\n",
      "96           817        668\n",
      "97           803        650\n",
      "98           734        800\n",
      "99           725        792\n",
      "\n",
      "\n",
      "Outputs/Labels of Testing Data:\n",
      "==============================\n",
      "\n",
      "  GPA\n",
      "     GPA\n",
      "80  2.71\n",
      "81  2.88\n",
      "82  2.63\n",
      "83  2.63\n",
      "84  2.88\n",
      "85  3.01\n",
      "86  2.60\n",
      "87  2.41\n",
      "88  2.88\n",
      "89  2.83\n",
      "90  3.08\n",
      "91  2.88\n",
      "92  2.85\n",
      "93  2.68\n",
      "94  2.53\n",
      "95  2.93\n",
      "96  2.98\n",
      "97  3.35\n",
      "98  2.96\n",
      "99  3.26\n"
     ]
    }
   ],
   "source": [
    "# Splitting Input Vectors and Outputs/Labels of Testing Data\n",
    "\n",
    "'''\n",
    "*---------------- SPLIT_INPUT_VECTORS_AND_LABELS --------------*\n",
    "|        Function: iloc()                                      |\n",
    "|            Purpose: Splitting Input Vector and Labels        |\n",
    "|        Arguments:                                            |\n",
    "|            Attribute: Name or Location Attribute to Split    |\n",
    "|        Return:                                               |\n",
    "|            Attribute: Split Attributes                       |\n",
    "*--------------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "print(\"\\n\\nInputs Vectors (Feature Vectors) of Testing Data:\")\n",
    "print(\"=================================================\\n\")\n",
    "input_vector_test = testing_data.iloc[:, 0:2]\n",
    "print(input_vector_test)\n",
    "\n",
    "print(\"\\n\\nOutputs/Labels of Testing Data:\")\n",
    "print(\"==============================\\n\")\n",
    "print(\"  GPA\")\n",
    "output_label_test = testing_data.iloc[:, 2:]\n",
    "print(output_label_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7.2: Load the Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Saved Model\n",
    "\n",
    "''' \n",
    "*------------------- LOAD_SAVED_MODEL --------------------------*\n",
    "|         Function: load()                                      |\n",
    "|               Purpose: Method to Load Previously Saved Model  |\n",
    "|         Arguments:                                            |\n",
    "|               Model: Trained Model                            |\n",
    "|         Return:                                               |\n",
    "|               File: Saved Model will be Loaded in Memory      |\n",
    "*---------------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "# Load the Saved Model\n",
    "\n",
    "model = pickle.load(open('svr_trained_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7.3: Evaluate the Machine Learning Model\n",
    "### Step 7.3.1: Make Predictions with the Trained Models on Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Predictions Returned by svr_trained_model:\n",
      "==========================================\n",
      "\n",
      "    Matric Marks  FSc Marks   GPA  Predictions\n",
      "80           578        648  2.71         2.08\n",
      "81           905        762  2.88         2.51\n",
      "82           806        684  2.63         2.25\n",
      "83           686        798  2.63         2.55\n",
      "84           784        676  2.88         2.22\n",
      "85           729        716  3.01         2.32\n",
      "86           826        750  2.60         2.45\n",
      "87           622        616  2.41         2.00\n",
      "88           744        610  2.88         2.02\n",
      "89           895        646  2.83         2.17\n",
      "90           662        676  3.08         2.18\n",
      "91           743        756  2.88         2.44\n",
      "92           814        764  2.85         2.49\n",
      "93           686        548  2.68         1.82\n",
      "94           796        598  2.53         2.00\n",
      "95           783        650  2.93         2.14\n",
      "96           817        668  2.98         2.21\n",
      "97           803        650  3.35         2.15\n",
      "98           734        800  2.96         2.57\n",
      "99           725        792  3.26         2.54\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Machine Learning Model\n",
    "\n",
    "''' \n",
    "*--------------------- EVALUATE_MACHINE_LEARNING_MODEL ----------------------*\n",
    "|       Function: Predict()                                                  |\n",
    "|             Purpose: Make a Prediction using Algorithm on Test Data        |\n",
    "|       Arguments:                                                           |\n",
    "|            Testing Data: Provide Test data to the Trained Model            |\n",
    "|       Return:                                                              |\n",
    "|            Predictions: Model return Predictions                           |\n",
    "*----------------------------------------------------------------------------* \n",
    "'''\n",
    "\n",
    "# Provide Test data to the Trained Model\n",
    "\n",
    "model_predictions = model.predict(input_vector_test)\n",
    "testing_data.copy(deep=True)\n",
    "pd.options.mode.chained_assignment = None\n",
    "testing_data[\"Predictions\"] = np.round(model_predictions,2)\n",
    "\n",
    "# Save the Predictions into CSV File\n",
    "\n",
    "testing_data.to_csv(r'model-predictions.csv', index = False, header = True)\n",
    "\n",
    "model_predictions = testing_data \n",
    "print(\"\\n\\nPredictions Returned by svr_trained_model:\")\n",
    "print(\"==========================================\\n\")\n",
    "print(model_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7.4: Calculate the Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Mean Absolute Error:\n",
      "===============\n",
      "\n",
      "0.59\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Root Mean Squared Error\n",
    "\n",
    "''' \n",
    "/*------------------------ CALCULATE_ROOT_MEAN_SQUARE_ERROR -----------------*\n",
    "|          Function: mean_squared_error()                              |\n",
    "|                Purpose: Evaluate the algorithm on Testing data       |\n",
    "|          Arguments:                                                  |\n",
    "|                Prediction: Predicted values                          |\n",
    "|                Label: Actual values                                  |\n",
    "|          Return:                                                     |\n",
    "|                Root Mean Squared Error                               |\n",
    "*----------------------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "# Calculate the Root Mean Squared Error\n",
    "\n",
    "model_mbe = mean_absolute_error(model_predictions[\"GPA\"],model_predictions[\"Predictions\"])\n",
    "\n",
    "print(\"\\n\\nMean Absolute Error:\")\n",
    "print(\"=======================\\n\")\n",
    "print(round(model_mbe,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Execute the Application Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8.1: Take Input from User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Please enter your Matric Marks : 871\n",
      "\n",
      "Please enter your FSc Marks : 830\n"
     ]
    }
   ],
   "source": [
    "# Take Input from User\n",
    "\n",
    "''' \n",
    "*---------------- TAKE_USER_INPUT ----------------*\n",
    "'''\n",
    "\n",
    "matric_marks_input = input(\"\\nPlease enter your Matric Marks : \").strip()\n",
    "fsc_marks_input = input(\"\\nPlease enter your FSc Marks : \").strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8.2: Convert User Input into Feature Vector (Exactly Same as Feature Vectors of Sample Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "User Input Feature Vector:\n",
      "==========================\n",
      "\n",
      "  Matric Marks FSC Marks\n",
      "0          871       830\n"
     ]
    }
   ],
   "source": [
    "# Convert User Input into Feature Vector\n",
    "\n",
    "user_input = pd.DataFrame({ 'Matric Marks': [matric_marks_input],'FSC Marks': [fsc_marks_input]})\n",
    "\n",
    "print(\"\\n\\nUser Input Feature Vector:\")\n",
    "print(\"==========================\\n\")\n",
    "print(user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8.3: Label Encoding of Feature Vector (Exactly Same as Label Encoded Feature Vectors of Sample Data)\n",
    "    o\tAs Input of Unseen Instance (Matric Marks and FSc Marks  Attributes) is already in Numeric Representation.\n",
    "    o\tTherefore, we will not Label Encode the Input of Unseen Instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8.4: Load the Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Saved Model\n",
    "\n",
    "''' \n",
    "*----------------------- LOAD_SAVED_MODEL --------------------------*\n",
    "|         Function: load()                                          |\n",
    "|             Purpose: Method to Load Previously Saved Model        |\n",
    "|         Arguments:                                                |\n",
    "|               Model: Trained Model                                |\n",
    "|         Return:                                                   |\n",
    "|               File: Saved Model will be Loaded in Memory          |\n",
    "*-------------------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "# Load the Saved Model\n",
    "\n",
    "model = pickle.load(open('svr_trained_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8.5: Model Prediction\n",
    "### Step 8.5.1: Apply Model on the Label Encoded Feature Vector of unseen instance and return Prediction to the User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+\n",
      "|        ** Prediction **        |\n",
      "+--------------------------------+\n",
      "|              2.7               |\n",
      "+--------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Prediction of Unseen Instance\n",
    "\n",
    "''' \n",
    "*----------------------------  MODEL_PREDICTION --------------------------*\n",
    "|           Function: predict()                                           |\n",
    "|                 Purpose: Use Trained Model to Predict the Output        |\n",
    "|                          of Unseen Instances                            |\n",
    "|           Arguments:                                                    |\n",
    "|                 User Data: Label Encoded Feature Vector of              |\n",
    "|                            Unseen Instances                             |\n",
    "|           Return:                                                       |\n",
    "|                 GPA                                                     |\n",
    "*-------------------------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "# Make a Prediction on Unseen Data\n",
    "\n",
    "predicted_gpa = model.predict(user_input)\n",
    "\n",
    "# Add the Prediction in a Pretty Table\n",
    "\n",
    "pretty_table = PrettyTable()\n",
    "pretty_table.add_column(\"       ** Prediction **       \",np.round(predicted_gpa,2))\n",
    "print(pretty_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9: Execute the Feedback Phase\n",
    "## A Two-Step Process\n",
    "### Step 01: After some time, take Feedback from\n",
    "    o\tDomain Experts and Users on deployed GPA Prediction System\n",
    "### Step 02: Make a List of Possible Improvements based on Feedback received"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 10: Improve Model based on Feedback\n",
    "### There is Always Room for Improvement\n",
    "### Based on Feedback from Domain Experts and Users\n",
    "    o\tImprove your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<center> <h3 style=\"color:blue\">==========================================================</h3> </center>\n",
    "<center> <h3 style=\"color:green\">JAZAK ALLAH KHAIR</h3> \n",
    "<center> <h3 style=\"color:blue\">==========================================================</h3> </center>\n",
    "<br><br><br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
